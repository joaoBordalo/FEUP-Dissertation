\chapter*{Abstract}

Nowadays computational platforms have been evolving to the high computational power direction, however it requires a lot of energy to achieve such high performance with single but powerful processing unit.
To manage this energy cost and keep with high performance, computers are built under the assumption of heterogeneous systems, in other words, computers that have different kind of processing units with different functions, such as CPU, GPU, Xeon Phi and FPGA. 
So, developers should take advantage of parallel activity and scheduling tasks by using the various parts of the heterogeneous systems.

Now the problem is how to efficiently achieve the highest performance possible when running software applications by taking the most advantage of such heterogeneous systems without jeopardizing the application performance and its results. 
Overall, the problem consists in the coexistence work of multicore specs, its parallelism and its shared cache problems; CPU parallelism and scheduling tasks; performance.

For this problem's solution is expected to find patterns and variables that helps tuning application with the best performance main goal in mind. Detecting these patterns and variables that improve applications, by making them parallelized, helps in the progression of how to make automatic paralleled code, since now-a-days making parallel code requires a lot of effort and time.

This kind of solution requires some validation process and metrics to make sure that it is doing its work and with proper results. To do so, the idea of the process' validation is going to be about comparing the behaviour of three different codes: a version of  a serialized code; a version of the same code but with an expert manually paralleling it; and a version of the serialized code but «automatically» parallelized by a tool called Kremlin. The metric that was used to compare these three code versions is execution time in different experience environment.

The application of this work will help developing better automatic tools to make parallel code, which means in a long term, developers will have less burdened about creating parallel code, consequently, saving them time.



applications will achieve its highest performance possible in an automatic way and developers will have less burdened about creating parallel code, consequently, saving them time.

\chapter*{Resumo}

Atualmente as plataformas computacionais têm vindo a evoluir na direção do elevado poder computacional, no entanto, estas requerem uma quantidade enorme de energia para atingir elevado desempenho individualmente.
De modo a gerir este custo energético e manter a elevada performance, os computadores são construídos sobre a assunção de sistemas heterogéneos, isto é, computadores compostos por diferentes tipos de unidades de processamentos com diferentes funcionalidades, como por exemplo, CPU,GPU, Xeon Phi e FPGA.
É neste sentido que os programadores devem tirar proveito de atividade paralela e escalonamento de tarefas recorrendo às várias partes que compõem o sistema heterogéneo.

O problema incide sobre como atingir de forma eficiente o maior desempenho possível quando se corre uma aplicação de software, tirando o maior proveito dos sistemas heterogéneos sem prejudicar o resultado e o desempenho da aplicação.

Para solucionar este problema é esperado encontrar/padrões e variáveis que ajudem a afinar applicações com o principal objetivo de atingir a melhor performance em mente. Detetar estes padrões e variáveis que melhoram applicações, colocando-as paralelas, ajuda no avanço de como fazer código aparaelelo automáticamente, uma vez que nos dias de hoje fazer código paralelo requer muito tempo e esforço.

Este tipo de solução requer um processo de validação e métricas para assegurar que se está a fazer o trabalho corretamente e com resultados aceitáveis. Para tal, a ideia da validação do processo consiste em comparar o comportamento de três diferentes códigos: uma versão sequencial de um código; a versão deste mesmo código mas paralelizada por um perito; e a versão do código sequencial mas paralelizado «automaticamente» por uma ferramenenta denominada de Kremlin. A métrica que foi utilizada para comprar estas três versões de código é o tempo de execução em diferentes ambientes experimentais

A aplicação deste trabalho irá ajudar a desenvolver melhores ferramentas para fazer código paralelo automático, siginificando que, a longo prazo, programadores estarão menos sobrecarregados a criarem código paralelo o que, consequentemente, poupar-lhes-á tempo.



